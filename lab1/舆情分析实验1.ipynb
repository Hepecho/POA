{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "舆情分析实验（1）文本主题分类\n",
    "==================================\n",
    "\n",
    "实验目的\n",
    "---------------------\n",
    "   - 熟悉简单的文本处理流程和神经网络文本分类模型\n",
    "   \n",
    "     文本分类是将文本按照一定的标准进行分类，比如新闻可以按照内容主题分为体育、科学等等。分类的“规则”可以由人确定，也可以用算法从有标签数据中自动归纳。人工制定分类规则可能并不容易，比如要区分体育和科学新闻，以有没有出现体育项目和运动员姓名来分类是可行的，但制定查找表并不容易，并且不能排除主要讲科学的新闻中出现这些词。自动算法帮助我们从文本中提取特征进行分类，并具有良好的性能和适应性。\n",
    "       - 利用简单的神经网络对文本主题进行分类\n",
    "       \n",
    "       输入：一段文本\n",
    "       \n",
    "       输出：预先定义好的主题类别，如：体育、科学等\n",
    "       \n",
    "       \n",
    "   - 初步了解深度学习框架pytorch的使用\n",
    "   \n",
    "     pytorch是一个开源深度学习框架，是一个基于Python的可续计算包，提供两个高级功能：1、具有强大的GPU加速的张量计算（如NumPy）。2、包含自动求导系统的深度神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验环境\n",
    "---------------------\n",
    "   - Anaconda3（python==3.9）\n",
    "   \n",
    "   - pytorch（pytorch==1.12.1）\n",
    "      - pytorch是一个开源的深度学习框架，能够利用GPU加速计算\n",
    "   \n",
    "   - torchtext（torchtext==0.13.1）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验数据\n",
    "---------------------\n",
    "\n",
    "新闻数据集AG_NEWS\n",
    "\n",
    "AG_NEWS数据集由4大类主题\n",
    "\n",
    "(\"World\",\"Sports\",\"Business\",\"Sci/Tech\")\n",
    "\n",
    "的新闻的标题和描述字段组合而成，每类包含 30,000 个训练和 1,900 个测试样本。\n",
    "\n",
    "如不能自动下载请访问以下链接\n",
    "\n",
    "\n",
    "train:`https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv`\n",
    "\n",
    "test:`https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验步骤\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "访问原始数据集\n",
    "---------------------\n",
    "\n",
    "torchtext 库提供了一些原始数据集迭代器，它们给出原始文本字符串。 例如，“AG_NEWS”数据集迭代器将原始数据以标签和文本的元组给出。\n",
    "\n",
    "(\"World\",\"Sports\",\"Business\",\"Sci/Tech\")对应于标签(\"1\",\"2\",\"3\",\"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "path = r''\n",
    "train_iter = AG_NEWS(root=path, split='train')\n",
    "train_iter = iter(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::\n",
    "\n",
    "    next(train_iter)\n",
    "    >>> (3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - \n",
    "    Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green \n",
    "    again.\")\n",
    "\n",
    "    next(train_iter)\n",
    "    >>> (3, 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private \n",
    "    investment firm Carlyle Group,\\\\which has a reputation for making well-timed \n",
    "    and occasionally\\\\controversial plays in the defense industry, has quietly \n",
    "    placed\\\\its bets on another part of the market.')\n",
    "\n",
    "    next(train_iter)\n",
    "    >>> (3, \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring \n",
    "    crude prices plus worries\\\\about the economy and the outlook for earnings are \n",
    "    expected to\\\\hang over the stock market next week during the depth of \n",
    "    the\\\\summer doldrums.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3,\n \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3,\n 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.')"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3,\n \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备数据处理管道\n",
    "---------------------------------\n",
    "\n",
    "第一步是使用原始训练数据集构建词汇表。`get_tokenizer`函数对文本进行分词。这里我们使用内置函数`build_vocab_from_iterator` 接受迭代器,它能自动构建词汇表，并把传入的文本字符串转成代表token的整数序列。还可以将任何特殊符号自主添加到词汇表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "# 分词\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "print('done')\n",
    "# 用<unk>填充那些不在词表中的词。\n",
    "# 词表很难包括所有可能出现的词，这称为out of vocabulary问题（OOV）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab将token列表转换为整数。\n",
    "\n",
    "::\n",
    "\n",
    "     vocab(['here', 'is', 'an', 'example'])\n",
    "     >>> [475, 21, 30, 5286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[475, 21, 30, 5297]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本管道根据词汇表中定义的token查找表将文本字符串转换为整数列表。标签管道将标签转换为整数。 例如，\n",
    "\n",
    "::\n",
    "\n",
    "     text_pipeline('here is the an example')\n",
    "     >>> [475, 21, 2, 30, 5286]\n",
    "     label_pipeline('3')\n",
    "     >>> 2\n",
    "\n",
    "注意'3'是字符串格式，转换成整数2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据批处理函数和加载器\n",
    "--------------------------------\n",
    "\n",
    "`torch.utils.data.DataLoader `\n",
    "它与实现\"getitem()\"和\"len()\"的数据集类一起使用，并表示从索引/键到数据样本的映射。\n",
    "\n",
    "在发送到模型之前，``collat​​e_fn`` 函数处理从``DataLoader`` 读取的一批样本。 ``collat​​e_fn`` 的输入是在``DataLoader`` 中具有大小batch的一批数据，``collat​​e_fn`` 根据之前声明的数据处理函数对其进行处理。\n",
    "\n",
    "在这个例子中，原始数据批量输入中的文本条目被打包到一个列表中，并连接为 nn.EmbeddingBag 输入的单个张量。offsets是偏移量的张量，用于表示文本张量中单个序列的开始索引。label是保存单个文本条目标签的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 检测是否有安装了cuda的显卡可用\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "        # 所谓偏移量可以理解为该文本的长度\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    # .cumsum(dim=0) 第1行不动，累加到其他行\n",
    "    text_list = torch.cat(text_list)  # 连接\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "print('done')\n",
    "# shuffle=True将打乱数据集，batch_size使得加载器每次读取该数量的条目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型\n",
    "----------------\n",
    "\n",
    "该模型由 `nn.EmbeddingBag层和用于分类目的的线性层组成。\n",
    "\n",
    "尽管此处的每条文本具有不同的长度，但 nn.EmbeddingBag 模块在此处不需要填充，因为文本长度保存在偏移量中。\n",
    "\n",
    "\n",
    "![jupyter](https://pytorch.org/tutorials/_images/text_sentiment_ngrams_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# .embedding实际上是一个查找表，一般用来存储词嵌入并通过indices从embedding中恢复词嵌入\n",
    "# EmbeddingBag就是把查找表整合成一个embedding，当不需要具体查表获得embedding，\n",
    "# 只需要一个整合结果时，它比两阶段操作Embedding + sum/mean/max(dim=0)更高效\n",
    "# sparse设置成True时参数weight为稀疏tensor。\n",
    "# 所谓稀疏tensor是说反向传播时只更新当前使用词的embedding，加快更新速度\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class, hidden_dim=128):\n",
    "        \"\"\"\n",
    "        vocab_size: 词汇表大小，vocab将token列表转换为整数\n",
    "        enbed_dim: 词嵌入维度，64\n",
    "        num_class: 文本类的数目，4\n",
    "        hidden_dim：新增的隐藏层维度, default=128\n",
    "        \"\"\"\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        # self.embedding.weight.requires_grad = False\n",
    "        # requires_grad固定部分参数进行网络训练\n",
    "        # self.fc = nn.Linear(embed_dim, num_class) #这个就是线性层\n",
    "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.active=torch.nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        # self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        # self.fc.bias.data.zero_()\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        z1 = self.fc1(embedded)\n",
    "        a1 = self.active(z1)\n",
    "        y_hat = self.fc2(a1)\n",
    "        return y_hat\n",
    "        # return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "固定随机数种子\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=6):\n",
    "\n",
    "    #random.seed(seed)\n",
    "    # os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    #np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "启动一个实例\n",
    "--------------------\n",
    "\n",
    "``AG_NEWS`` 数据集有四个标签，因此类的数量是四个。\n",
    "\n",
    "::\n",
    "\n",
    "    1： 世界\n",
    "    2 : 运动\n",
    "    3 : 商务\n",
    "    4 : 科学/技术\n",
    "\n",
    "我们构建了一个嵌入维度为 64 的模型。类的数量等于标签的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0921, -0.1805,  0.1189,  ...,  0.4112, -0.0949, -0.3417],\n",
      "        [-0.3436, -0.1945, -0.0684,  ..., -0.0204, -0.3853,  0.3721],\n",
      "        [ 0.4780,  0.1204, -0.2799,  ..., -0.3613, -0.3977, -0.4234],\n",
      "        ...,\n",
      "        [-0.0106, -0.2680,  0.1795,  ...,  0.0176,  0.3184, -0.3250],\n",
      "        [-0.2188, -0.1860,  0.0615,  ...,  0.4610,  0.2756, -0.1240],\n",
      "        [ 0.0546, -0.3117,  0.4742,  ..., -0.2603,  0.2283, -0.2978]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "hidsize = 32\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class, hidsize).to(device)\n",
    "# 打印embedding参数\n",
    "print(model.embedding.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义用于训练模型和评估结果的函数。\n",
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拆分数据集并运行模型\n",
    "---------------------\n",
    "\n",
    "由于原始``AG_NEWS`` 没有用来验证的数据集，我们拆分\n",
    "将训练数据集转换为训练集/验证集，分割比为 0.95（训练集）和\n",
    "0.05（验证集）。我们使用\n",
    "`torch.utils.data.dataset.random_split`\n",
    "\n",
    "`CrossEntropyLoss`\n",
    "交叉熵损失函数，分类问题常用。\n",
    "\n",
    "`SGD`\n",
    "随机梯度下降法作为优化器。最初的\n",
    "学习率设置为 5.0。\n",
    "\n",
    "`StepLR`\n",
    "用来调整学习率。\n",
    "\n",
    "CPU参考运行时间：7分钟\n",
    "\n",
    "GPU参考运行时间：5分钟"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting_2 = {\n",
    "    &emsp;双线性层\n",
    "    &emsp;无激活函数\n",
    "    &emsp;Hyperparameters{\n",
    "        &emsp;&emsp;EPOCHS = 10\n",
    "        &emsp;&emsp;LR = 5\n",
    "        &emsp;&emsp;BATCH_SIZE = 64\n",
    "    &emsp;}\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/14250 batches | accuracy    0.420\n",
      "| epoch   1 |  1000/14250 batches | accuracy    0.660\n",
      "| epoch   1 |  1500/14250 batches | accuracy    0.754\n",
      "| epoch   1 |  2000/14250 batches | accuracy    0.794\n",
      "| epoch   1 |  2500/14250 batches | accuracy    0.808\n",
      "| epoch   1 |  3000/14250 batches | accuracy    0.828\n",
      "| epoch   1 |  3500/14250 batches | accuracy    0.846\n",
      "| epoch   1 |  4000/14250 batches | accuracy    0.849\n",
      "| epoch   1 |  4500/14250 batches | accuracy    0.852\n",
      "| epoch   1 |  5000/14250 batches | accuracy    0.854\n",
      "| epoch   1 |  5500/14250 batches | accuracy    0.860\n",
      "| epoch   1 |  6000/14250 batches | accuracy    0.859\n",
      "| epoch   1 |  6500/14250 batches | accuracy    0.871\n",
      "| epoch   1 |  7000/14250 batches | accuracy    0.866\n",
      "| epoch   1 |  7500/14250 batches | accuracy    0.879\n",
      "| epoch   1 |  8000/14250 batches | accuracy    0.868\n",
      "| epoch   1 |  8500/14250 batches | accuracy    0.875\n",
      "| epoch   1 |  9000/14250 batches | accuracy    0.874\n",
      "| epoch   1 |  9500/14250 batches | accuracy    0.869\n",
      "| epoch   1 | 10000/14250 batches | accuracy    0.881\n",
      "| epoch   1 | 10500/14250 batches | accuracy    0.879\n",
      "| epoch   1 | 11000/14250 batches | accuracy    0.881\n",
      "| epoch   1 | 11500/14250 batches | accuracy    0.885\n",
      "| epoch   1 | 12000/14250 batches | accuracy    0.882\n",
      "| epoch   1 | 12500/14250 batches | accuracy    0.871\n",
      "| epoch   1 | 13000/14250 batches | accuracy    0.880\n",
      "| epoch   1 | 13500/14250 batches | accuracy    0.883\n",
      "| epoch   1 | 14000/14250 batches | accuracy    0.886\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 44.34s | valid accuracy    0.885 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/14250 batches | accuracy    0.899\n",
      "| epoch   2 |  1000/14250 batches | accuracy    0.906\n",
      "| epoch   2 |  1500/14250 batches | accuracy    0.897\n",
      "| epoch   2 |  2000/14250 batches | accuracy    0.897\n",
      "| epoch   2 |  2500/14250 batches | accuracy    0.910\n",
      "| epoch   2 |  3000/14250 batches | accuracy    0.900\n",
      "| epoch   2 |  3500/14250 batches | accuracy    0.905\n",
      "| epoch   2 |  4000/14250 batches | accuracy    0.895\n",
      "| epoch   2 |  4500/14250 batches | accuracy    0.891\n",
      "| epoch   2 |  5000/14250 batches | accuracy    0.901\n",
      "| epoch   2 |  5500/14250 batches | accuracy    0.900\n",
      "| epoch   2 |  6000/14250 batches | accuracy    0.898\n",
      "| epoch   2 |  6500/14250 batches | accuracy    0.904\n",
      "| epoch   2 |  7000/14250 batches | accuracy    0.909\n",
      "| epoch   2 |  7500/14250 batches | accuracy    0.905\n",
      "| epoch   2 |  8000/14250 batches | accuracy    0.912\n",
      "| epoch   2 |  8500/14250 batches | accuracy    0.911\n",
      "| epoch   2 |  9000/14250 batches | accuracy    0.903\n",
      "| epoch   2 |  9500/14250 batches | accuracy    0.907\n",
      "| epoch   2 | 10000/14250 batches | accuracy    0.909\n",
      "| epoch   2 | 10500/14250 batches | accuracy    0.905\n",
      "| epoch   2 | 11000/14250 batches | accuracy    0.903\n",
      "| epoch   2 | 11500/14250 batches | accuracy    0.897\n",
      "| epoch   2 | 12000/14250 batches | accuracy    0.903\n",
      "| epoch   2 | 12500/14250 batches | accuracy    0.908\n",
      "| epoch   2 | 13000/14250 batches | accuracy    0.915\n",
      "| epoch   2 | 13500/14250 batches | accuracy    0.903\n",
      "| epoch   2 | 14000/14250 batches | accuracy    0.905\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 42.67s | valid accuracy    0.906 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/14250 batches | accuracy    0.930\n",
      "| epoch   3 |  1000/14250 batches | accuracy    0.920\n",
      "| epoch   3 |  1500/14250 batches | accuracy    0.921\n",
      "| epoch   3 |  2000/14250 batches | accuracy    0.919\n",
      "| epoch   3 |  2500/14250 batches | accuracy    0.917\n",
      "| epoch   3 |  3000/14250 batches | accuracy    0.912\n",
      "| epoch   3 |  3500/14250 batches | accuracy    0.923\n",
      "| epoch   3 |  4000/14250 batches | accuracy    0.924\n",
      "| epoch   3 |  4500/14250 batches | accuracy    0.919\n",
      "| epoch   3 |  5000/14250 batches | accuracy    0.916\n",
      "| epoch   3 |  5500/14250 batches | accuracy    0.914\n",
      "| epoch   3 |  6000/14250 batches | accuracy    0.913\n",
      "| epoch   3 |  6500/14250 batches | accuracy    0.910\n",
      "| epoch   3 |  7000/14250 batches | accuracy    0.920\n",
      "| epoch   3 |  7500/14250 batches | accuracy    0.913\n",
      "| epoch   3 |  8000/14250 batches | accuracy    0.918\n",
      "| epoch   3 |  8500/14250 batches | accuracy    0.925\n",
      "| epoch   3 |  9000/14250 batches | accuracy    0.923\n",
      "| epoch   3 |  9500/14250 batches | accuracy    0.910\n",
      "| epoch   3 | 10000/14250 batches | accuracy    0.915\n",
      "| epoch   3 | 10500/14250 batches | accuracy    0.925\n",
      "| epoch   3 | 11000/14250 batches | accuracy    0.918\n",
      "| epoch   3 | 11500/14250 batches | accuracy    0.907\n",
      "| epoch   3 | 12000/14250 batches | accuracy    0.921\n",
      "| epoch   3 | 12500/14250 batches | accuracy    0.920\n",
      "| epoch   3 | 13000/14250 batches | accuracy    0.915\n",
      "| epoch   3 | 13500/14250 batches | accuracy    0.911\n",
      "| epoch   3 | 14000/14250 batches | accuracy    0.914\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 45.26s | valid accuracy    0.896 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/14250 batches | accuracy    0.937\n",
      "| epoch   4 |  1000/14250 batches | accuracy    0.934\n",
      "| epoch   4 |  1500/14250 batches | accuracy    0.942\n",
      "| epoch   4 |  2000/14250 batches | accuracy    0.935\n",
      "| epoch   4 |  2500/14250 batches | accuracy    0.941\n",
      "| epoch   4 |  3000/14250 batches | accuracy    0.945\n",
      "| epoch   4 |  3500/14250 batches | accuracy    0.944\n",
      "| epoch   4 |  4000/14250 batches | accuracy    0.945\n",
      "| epoch   4 |  4500/14250 batches | accuracy    0.940\n",
      "| epoch   4 |  5000/14250 batches | accuracy    0.938\n",
      "| epoch   4 |  5500/14250 batches | accuracy    0.938\n",
      "| epoch   4 |  6000/14250 batches | accuracy    0.938\n",
      "| epoch   4 |  6500/14250 batches | accuracy    0.946\n",
      "| epoch   4 |  7000/14250 batches | accuracy    0.943\n",
      "| epoch   4 |  7500/14250 batches | accuracy    0.941\n",
      "| epoch   4 |  8000/14250 batches | accuracy    0.945\n",
      "| epoch   4 |  8500/14250 batches | accuracy    0.947\n",
      "| epoch   4 |  9000/14250 batches | accuracy    0.945\n",
      "| epoch   4 |  9500/14250 batches | accuracy    0.943\n",
      "| epoch   4 | 10000/14250 batches | accuracy    0.938\n",
      "| epoch   4 | 10500/14250 batches | accuracy    0.945\n",
      "| epoch   4 | 11000/14250 batches | accuracy    0.947\n",
      "| epoch   4 | 11500/14250 batches | accuracy    0.943\n",
      "| epoch   4 | 12000/14250 batches | accuracy    0.946\n",
      "| epoch   4 | 12500/14250 batches | accuracy    0.943\n",
      "| epoch   4 | 13000/14250 batches | accuracy    0.943\n",
      "| epoch   4 | 13500/14250 batches | accuracy    0.942\n",
      "| epoch   4 | 14000/14250 batches | accuracy    0.945\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 45.00s | valid accuracy    0.916 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/14250 batches | accuracy    0.944\n",
      "| epoch   5 |  1000/14250 batches | accuracy    0.950\n",
      "| epoch   5 |  1500/14250 batches | accuracy    0.948\n",
      "| epoch   5 |  2000/14250 batches | accuracy    0.947\n",
      "| epoch   5 |  2500/14250 batches | accuracy    0.949\n",
      "| epoch   5 |  3000/14250 batches | accuracy    0.945\n",
      "| epoch   5 |  3500/14250 batches | accuracy    0.940\n",
      "| epoch   5 |  4000/14250 batches | accuracy    0.946\n",
      "| epoch   5 |  4500/14250 batches | accuracy    0.948\n",
      "| epoch   5 |  5000/14250 batches | accuracy    0.948\n",
      "| epoch   5 |  5500/14250 batches | accuracy    0.943\n",
      "| epoch   5 |  6000/14250 batches | accuracy    0.944\n",
      "| epoch   5 |  6500/14250 batches | accuracy    0.942\n",
      "| epoch   5 |  7000/14250 batches | accuracy    0.948\n",
      "| epoch   5 |  7500/14250 batches | accuracy    0.944\n",
      "| epoch   5 |  8000/14250 batches | accuracy    0.950\n",
      "| epoch   5 |  8500/14250 batches | accuracy    0.945\n",
      "| epoch   5 |  9000/14250 batches | accuracy    0.945\n",
      "| epoch   5 |  9500/14250 batches | accuracy    0.950\n",
      "| epoch   5 | 10000/14250 batches | accuracy    0.945\n",
      "| epoch   5 | 10500/14250 batches | accuracy    0.946\n",
      "| epoch   5 | 11000/14250 batches | accuracy    0.943\n",
      "| epoch   5 | 11500/14250 batches | accuracy    0.941\n",
      "| epoch   5 | 12000/14250 batches | accuracy    0.940\n",
      "| epoch   5 | 12500/14250 batches | accuracy    0.949\n",
      "| epoch   5 | 13000/14250 batches | accuracy    0.946\n",
      "| epoch   5 | 13500/14250 batches | accuracy    0.943\n",
      "| epoch   5 | 14000/14250 batches | accuracy    0.947\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 44.21s | valid accuracy    0.920 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/14250 batches | accuracy    0.953\n",
      "| epoch   6 |  1000/14250 batches | accuracy    0.949\n",
      "| epoch   6 |  1500/14250 batches | accuracy    0.942\n",
      "| epoch   6 |  2000/14250 batches | accuracy    0.946\n",
      "| epoch   6 |  2500/14250 batches | accuracy    0.942\n",
      "| epoch   6 |  3000/14250 batches | accuracy    0.952\n",
      "| epoch   6 |  3500/14250 batches | accuracy    0.952\n",
      "| epoch   6 |  4000/14250 batches | accuracy    0.950\n",
      "| epoch   6 |  4500/14250 batches | accuracy    0.949\n",
      "| epoch   6 |  5000/14250 batches | accuracy    0.956\n",
      "| epoch   6 |  5500/14250 batches | accuracy    0.944\n",
      "| epoch   6 |  6000/14250 batches | accuracy    0.951\n",
      "| epoch   6 |  6500/14250 batches | accuracy    0.954\n",
      "| epoch   6 |  7000/14250 batches | accuracy    0.950\n",
      "| epoch   6 |  7500/14250 batches | accuracy    0.947\n",
      "| epoch   6 |  8000/14250 batches | accuracy    0.952\n",
      "| epoch   6 |  8500/14250 batches | accuracy    0.949\n",
      "| epoch   6 |  9000/14250 batches | accuracy    0.949\n",
      "| epoch   6 |  9500/14250 batches | accuracy    0.943\n",
      "| epoch   6 | 10000/14250 batches | accuracy    0.952\n",
      "| epoch   6 | 10500/14250 batches | accuracy    0.944\n",
      "| epoch   6 | 11000/14250 batches | accuracy    0.945\n",
      "| epoch   6 | 11500/14250 batches | accuracy    0.944\n",
      "| epoch   6 | 12000/14250 batches | accuracy    0.950\n",
      "| epoch   6 | 12500/14250 batches | accuracy    0.952\n",
      "| epoch   6 | 13000/14250 batches | accuracy    0.941\n",
      "| epoch   6 | 13500/14250 batches | accuracy    0.946\n",
      "| epoch   6 | 14000/14250 batches | accuracy    0.947\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 41.96s | valid accuracy    0.921 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/14250 batches | accuracy    0.952\n",
      "| epoch   7 |  1000/14250 batches | accuracy    0.948\n",
      "| epoch   7 |  1500/14250 batches | accuracy    0.949\n",
      "| epoch   7 |  2000/14250 batches | accuracy    0.952\n",
      "| epoch   7 |  2500/14250 batches | accuracy    0.957\n",
      "| epoch   7 |  3000/14250 batches | accuracy    0.944\n",
      "| epoch   7 |  3500/14250 batches | accuracy    0.949\n",
      "| epoch   7 |  4000/14250 batches | accuracy    0.952\n",
      "| epoch   7 |  4500/14250 batches | accuracy    0.950\n",
      "| epoch   7 |  5000/14250 batches | accuracy    0.945\n",
      "| epoch   7 |  5500/14250 batches | accuracy    0.946\n",
      "| epoch   7 |  6000/14250 batches | accuracy    0.952\n",
      "| epoch   7 |  6500/14250 batches | accuracy    0.954\n",
      "| epoch   7 |  7000/14250 batches | accuracy    0.950\n",
      "| epoch   7 |  7500/14250 batches | accuracy    0.952\n",
      "| epoch   7 |  8000/14250 batches | accuracy    0.950\n",
      "| epoch   7 |  8500/14250 batches | accuracy    0.947\n",
      "| epoch   7 |  9000/14250 batches | accuracy    0.948\n",
      "| epoch   7 |  9500/14250 batches | accuracy    0.950\n",
      "| epoch   7 | 10000/14250 batches | accuracy    0.953\n",
      "| epoch   7 | 10500/14250 batches | accuracy    0.948\n",
      "| epoch   7 | 11000/14250 batches | accuracy    0.946\n",
      "| epoch   7 | 11500/14250 batches | accuracy    0.949\n",
      "| epoch   7 | 12000/14250 batches | accuracy    0.952\n",
      "| epoch   7 | 12500/14250 batches | accuracy    0.947\n",
      "| epoch   7 | 13000/14250 batches | accuracy    0.950\n",
      "| epoch   7 | 13500/14250 batches | accuracy    0.954\n",
      "| epoch   7 | 14000/14250 batches | accuracy    0.942\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 43.81s | valid accuracy    0.922 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/14250 batches | accuracy    0.947\n",
      "| epoch   8 |  1000/14250 batches | accuracy    0.954\n",
      "| epoch   8 |  1500/14250 batches | accuracy    0.954\n",
      "| epoch   8 |  2000/14250 batches | accuracy    0.957\n",
      "| epoch   8 |  2500/14250 batches | accuracy    0.950\n",
      "| epoch   8 |  3000/14250 batches | accuracy    0.952\n",
      "| epoch   8 |  3500/14250 batches | accuracy    0.948\n",
      "| epoch   8 |  4000/14250 batches | accuracy    0.956\n",
      "| epoch   8 |  4500/14250 batches | accuracy    0.952\n",
      "| epoch   8 |  5000/14250 batches | accuracy    0.952\n",
      "| epoch   8 |  5500/14250 batches | accuracy    0.954\n",
      "| epoch   8 |  6000/14250 batches | accuracy    0.951\n",
      "| epoch   8 |  6500/14250 batches | accuracy    0.954\n",
      "| epoch   8 |  7000/14250 batches | accuracy    0.947\n",
      "| epoch   8 |  7500/14250 batches | accuracy    0.952\n",
      "| epoch   8 |  8000/14250 batches | accuracy    0.943\n",
      "| epoch   8 |  8500/14250 batches | accuracy    0.950\n",
      "| epoch   8 |  9000/14250 batches | accuracy    0.952\n",
      "| epoch   8 |  9500/14250 batches | accuracy    0.949\n",
      "| epoch   8 | 10000/14250 batches | accuracy    0.953\n",
      "| epoch   8 | 10500/14250 batches | accuracy    0.951\n",
      "| epoch   8 | 11000/14250 batches | accuracy    0.951\n",
      "| epoch   8 | 11500/14250 batches | accuracy    0.951\n",
      "| epoch   8 | 12000/14250 batches | accuracy    0.953\n",
      "| epoch   8 | 12500/14250 batches | accuracy    0.954\n",
      "| epoch   8 | 13000/14250 batches | accuracy    0.953\n",
      "| epoch   8 | 13500/14250 batches | accuracy    0.942\n",
      "| epoch   8 | 14000/14250 batches | accuracy    0.954\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 48.76s | valid accuracy    0.919 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/14250 batches | accuracy    0.955\n",
      "| epoch   9 |  1000/14250 batches | accuracy    0.951\n",
      "| epoch   9 |  1500/14250 batches | accuracy    0.950\n",
      "| epoch   9 |  2000/14250 batches | accuracy    0.953\n",
      "| epoch   9 |  2500/14250 batches | accuracy    0.956\n",
      "| epoch   9 |  3000/14250 batches | accuracy    0.955\n",
      "| epoch   9 |  3500/14250 batches | accuracy    0.957\n",
      "| epoch   9 |  4000/14250 batches | accuracy    0.956\n",
      "| epoch   9 |  4500/14250 batches | accuracy    0.953\n",
      "| epoch   9 |  5000/14250 batches | accuracy    0.953\n",
      "| epoch   9 |  5500/14250 batches | accuracy    0.953\n",
      "| epoch   9 |  6000/14250 batches | accuracy    0.956\n",
      "| epoch   9 |  6500/14250 batches | accuracy    0.958\n",
      "| epoch   9 |  7000/14250 batches | accuracy    0.958\n",
      "| epoch   9 |  7500/14250 batches | accuracy    0.954\n",
      "| epoch   9 |  8000/14250 batches | accuracy    0.954\n",
      "| epoch   9 |  8500/14250 batches | accuracy    0.954\n",
      "| epoch   9 |  9000/14250 batches | accuracy    0.951\n",
      "| epoch   9 |  9500/14250 batches | accuracy    0.955\n",
      "| epoch   9 | 10000/14250 batches | accuracy    0.952\n",
      "| epoch   9 | 10500/14250 batches | accuracy    0.956\n",
      "| epoch   9 | 11000/14250 batches | accuracy    0.955\n",
      "| epoch   9 | 11500/14250 batches | accuracy    0.954\n",
      "| epoch   9 | 12000/14250 batches | accuracy    0.950\n",
      "| epoch   9 | 12500/14250 batches | accuracy    0.957\n",
      "| epoch   9 | 13000/14250 batches | accuracy    0.949\n",
      "| epoch   9 | 13500/14250 batches | accuracy    0.955\n",
      "| epoch   9 | 14000/14250 batches | accuracy    0.957\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 40.57s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/14250 batches | accuracy    0.955\n",
      "| epoch  10 |  1000/14250 batches | accuracy    0.959\n",
      "| epoch  10 |  1500/14250 batches | accuracy    0.956\n",
      "| epoch  10 |  2000/14250 batches | accuracy    0.959\n",
      "| epoch  10 |  2500/14250 batches | accuracy    0.955\n",
      "| epoch  10 |  3000/14250 batches | accuracy    0.953\n",
      "| epoch  10 |  3500/14250 batches | accuracy    0.954\n",
      "| epoch  10 |  4000/14250 batches | accuracy    0.960\n",
      "| epoch  10 |  4500/14250 batches | accuracy    0.955\n",
      "| epoch  10 |  5000/14250 batches | accuracy    0.955\n",
      "| epoch  10 |  5500/14250 batches | accuracy    0.954\n",
      "| epoch  10 |  6000/14250 batches | accuracy    0.954\n",
      "| epoch  10 |  6500/14250 batches | accuracy    0.946\n",
      "| epoch  10 |  7000/14250 batches | accuracy    0.959\n",
      "| epoch  10 |  7500/14250 batches | accuracy    0.952\n",
      "| epoch  10 |  8000/14250 batches | accuracy    0.954\n",
      "| epoch  10 |  8500/14250 batches | accuracy    0.955\n",
      "| epoch  10 |  9000/14250 batches | accuracy    0.956\n",
      "| epoch  10 |  9500/14250 batches | accuracy    0.952\n",
      "| epoch  10 | 10000/14250 batches | accuracy    0.957\n",
      "| epoch  10 | 10500/14250 batches | accuracy    0.954\n",
      "| epoch  10 | 11000/14250 batches | accuracy    0.953\n",
      "| epoch  10 | 11500/14250 batches | accuracy    0.958\n",
      "| epoch  10 | 12000/14250 batches | accuracy    0.949\n",
      "| epoch  10 | 12500/14250 batches | accuracy    0.954\n",
      "| epoch  10 | 13000/14250 batches | accuracy    0.954\n",
      "| epoch  10 | 13500/14250 batches | accuracy    0.959\n",
      "| epoch  10 | 14000/14250 batches | accuracy    0.953\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 37.37s | valid accuracy    0.924 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# 定义cache, 缓存epoch的结果\n",
    "cache = {\n",
    "    'epoch': [],\n",
    "    'acc': []\n",
    "}\n",
    "\n",
    "# Hyperparameters超参数\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate学习率\n",
    "BATCH_SIZE = 8 # batch size for training\n",
    "\n",
    "#定义损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#定义优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "path = r''\n",
    "train_iter, test_iter = AG_NEWS(root=path)\n",
    "# train_iter, test_iter是迭代器的形式，to_map_style_dataset将其\n",
    "# 转成DataLoader能读取的格式，参考torch.utils.data.Dataset类\n",
    "train_dataset = to_map_style_dataset(iter(train_iter))\n",
    "test_dataset = to_map_style_dataset(iter(test_iter))\n",
    "#train_dataset = AG_NEWS('train')\n",
    "#test_dataset = AG_NEWS('test')\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    cache['epoch'].append(epoch)\n",
    "    cache['acc'].append(accu_val)\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0921, -0.1805,  0.1189,  ...,  0.4112, -0.0949, -0.3417],\n",
      "        [-0.0752,  0.0599,  0.4923,  ...,  0.2468, -0.3721,  0.1878],\n",
      "        [ 0.1334,  0.1052, -0.0706,  ...,  0.0091, -0.1186, -0.0474],\n",
      "        ...,\n",
      "        [-0.0107, -0.2680,  0.1794,  ...,  0.0176,  0.3184, -0.3250],\n",
      "        [-0.2294, -0.1787,  0.0606,  ...,  0.4658,  0.2753, -0.1123],\n",
      "        [ 0.0602, -0.3091,  0.4774,  ..., -0.2638,  0.2307, -0.3002]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib auto\n",
    "\n",
    "sns.set(style='dark')\n",
    "sns.lineplot(x=\"epoch\", y=\"acc\", data=cache).set_xlim(0,11)\n",
    "# 添加文本标签\n",
    "for i in range(len(cache['epoch'])):\n",
    "    plt.text(cache['epoch'][i] + 0.2, cache['acc'][i], \"{:.3f}\".format(cache['acc'][i]))\n",
    "plt.show()\n",
    "# 打印embedding参数\n",
    "print(model.embedding.weight)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用测试数据集评估模型\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查测试数据集的结果…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.914\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试一条新闻\n",
    "---------------------\n",
    "\n",
    "使用该模型并测试一条高尔夫新闻（体育）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news\n"
     ]
    }
   ],
   "source": [
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text.to(device), torch.tensor([0]).to(device))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LSTM模型\n",
    "---------------------\n",
    "\n",
    "长短期记忆网络——通常被称为 LSTM，是一种特殊的 RNN，能够学习长期依赖性。由 Hochreiter 和 Schmidhuber（1997）提出。\n",
    "\n",
    "![jupyter](https://n.sinaimg.cn/spider202044/731/w1040h491/20200404/0bc7-irtymmw0458671.png)\n",
    "\n",
    "CPU参考运行时间：30分钟\n",
    "\n",
    "GPU参考运行时间：8分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers, bidirectional=False)\n",
    "        # num_layers定义了LSTM网络的层数，bidirectional表示是单向LSTM还是双向LSTM（BiLSTM）\n",
    "        self.fc = nn.Linear(hidden_size, num_class)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets).unsqueeze(1)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(embedded)\n",
    "        return self.fc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [57]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m train_iter \u001B[38;5;241m=\u001B[39m AG_NEWS(split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#train_iter = iter(AG_NEWS('train'))\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m num_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m([label \u001B[38;5;28;01mfor\u001B[39;00m (label, text) \u001B[38;5;129;01min\u001B[39;00m train_iter]))\n\u001B[0;32m      4\u001B[0m vocab_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(vocab)\n\u001B[0;32m      5\u001B[0m emsize \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m64\u001B[39m\n",
      "Input \u001B[1;32mIn [57]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      1\u001B[0m train_iter \u001B[38;5;241m=\u001B[39m AG_NEWS(split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#train_iter = iter(AG_NEWS('train'))\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m num_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m([label \u001B[38;5;28;01mfor\u001B[39;00m (label, text) \u001B[38;5;129;01min\u001B[39;00m train_iter]))\n\u001B[0;32m      4\u001B[0m vocab_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(vocab)\n\u001B[0;32m      5\u001B[0m emsize \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m64\u001B[39m\n",
      "File \u001B[1;32mD:\\Code_Program\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:525\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    523\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Decided against using `contextlib.nullcontext` for performance reasons\u001B[39;00m\n\u001B[0;32m    524\u001B[0m             _check_iterator_valid(datapipe, iterator_id)\n\u001B[1;32m--> 525\u001B[0m             response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m e\u001B[38;5;241m.\u001B[39mvalue\n",
      "File \u001B[1;32mD:\\Code_Program\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\grouping.py:41\u001B[0m, in \u001B[0;36mShardingFilterIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe):\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_of_instances \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance_id:\n\u001B[0;32m     43\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m item\n",
      "File \u001B[1;32mD:\\Code_Program\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:525\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    523\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Decided against using `contextlib.nullcontext` for performance reasons\u001B[39;00m\n\u001B[0;32m    524\u001B[0m             _check_iterator_valid(datapipe, iterator_id)\n\u001B[1;32m--> 525\u001B[0m             response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m e\u001B[38;5;241m.\u001B[39mvalue\n",
      "File \u001B[1;32mD:\\Code_Program\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combinatorics.py:122\u001B[0m, in \u001B[0;36mShufflerIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T_co]:\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enabled:\n\u001B[1;32m--> 122\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe:\n\u001B[0;32m    123\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m x\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Code_Program\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:525\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    523\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Decided against using `contextlib.nullcontext` for performance reasons\u001B[39;00m\n\u001B[0;32m    524\u001B[0m             _check_iterator_valid(datapipe, iterator_id)\n\u001B[1;32m--> 525\u001B[0m             response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m e\u001B[38;5;241m.\u001B[39mvalue\n",
      "File \u001B[1;32mD:\\Code_Program\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:116\u001B[0m, in \u001B[0;36mMapperIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T_co]:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe:\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Code_Program\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:79\u001B[0m, in \u001B[0;36mMapperIterDataPipe._apply_fn\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     76\u001B[0m         output_col \u001B[38;5;241m=\u001B[39m output_col[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_col \u001B[38;5;241m=\u001B[39m output_col\n\u001B[1;32m---> 79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply_fn\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_col \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_col \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(data)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "#train_iter = iter(AG_NEWS('train'))\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "LSTM_model = LSTM(vocab_size, emsize, num_class, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    LSTM_model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = LSTM_model(text, offsets).squeeze()\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(LSTM_model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    LSTM_model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = LSTM_model(text, offsets).squeeze()\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# 定义cache, 缓存epoch的结果\n",
    "cache = {\n",
    "    'epoch': [],\n",
    "    'acc': []\n",
    "}\n",
    "\n",
    "# Hyperparameters超参数\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate学习率\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "  \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(LSTM_model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "# train_iter, test_iter = AG_NEWS()\n",
    "# train_dataset = to_map_style_dataset(train_iter)\n",
    "# test_dataset = to_map_style_dataset(test_iter)\n",
    "path = r''\n",
    "train_iter, test_iter = AG_NEWS(root=path)\n",
    "train_dataset = to_map_style_dataset(iter(train_iter))\n",
    "test_dataset = to_map_style_dataset(iter(test_iter))\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    cache['epoch'].append(epoch)\n",
    "    cache['acc'].append(accu_val)\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style='dark')\n",
    "sns.lineplot(x=\"epoch\", y=\"acc\", data=cache).set_xlim(0, 11)\n",
    "# 添加文本标签\n",
    "for i in range(len(cache['epoch'])):\n",
    "    plt.text(cache['epoch'][i] + 0.2, cache['acc'][i] - 0.001, \"{:.3f}\".format(cache['acc'][i]), fontsize=10)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验要求\n",
    "-------------------\n",
    "\n",
    "   - 配置实验环境，阅读教程样例并运行，理解实验流程\n",
    "    \n",
    "   - 将教程中的单层线性模型改为双层模型，并比较至少三组超参数和两种激活函数，写入实验报告\n",
    "       - 需要了解的内容：激活函数，如nn.Tanh()等\n",
    "   \n",
    "   - 解除TextClassificationModel中一行代码的注释，再次运行模型，比较前后结果，并解释为什么，写入实验报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文献\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交时间\n",
    "----------------\n",
    "\n",
    "10月23日前\n",
    "\n",
    "提交格式：word或pdf\n",
    "`学号-姓名-实验1`\n",
    "\n",
    "提交地址:\n",
    "`https://workspace.jianguoyun.com/inbox/collect/8d90cb29f6e04a1c87edb7647768c046/submit`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
